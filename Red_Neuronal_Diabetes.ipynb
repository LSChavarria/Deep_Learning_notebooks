{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Red_Neuronal_Diabetes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrnhqeD74Pez"
      },
      "source": [
        "#Fuente: https://unipython.com/desarrolla-primera-red-neural-python-keras-paso-paso/ \r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "import numpy\r\n",
        "# Fija las semillas aleatorias para la reproducibilidad\r\n",
        "numpy.random.seed(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upQnJCyK6LZC"
      },
      "source": [
        "# carga los datos\r\n",
        "dataset = numpy.genfromtxt('/content/pima-indians-diabetes.csv', delimiter=',')\r\n",
        "# dividido en variables de entrada (X) y salida (Y)\r\n",
        "X = dataset[:,0:8]\r\n",
        "Y = dataset[:,8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN37gv8M6pOl"
      },
      "source": [
        "# crea el modelo\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\r\n",
        "model.add(Dense(8, activation='relu'))\r\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-AJlRxY7tkP"
      },
      "source": [
        "# Compila el modelo\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIcAUHcJ8Ia9",
        "outputId": "ee288942-e63c-433a-b136-244e0c7ee232"
      },
      "source": [
        "# Ajusta el modelo\r\n",
        "model.fit(X, Y, epochs=150, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "77/77 [==============================] - 1s 2ms/step - loss: 10.4026 - accuracy: 0.6417\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 4.4325 - accuracy: 0.6269\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 2.4264 - accuracy: 0.6102\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 1.7839 - accuracy: 0.6663\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 1.8084 - accuracy: 0.5954\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 1.2820 - accuracy: 0.6604\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 1.0817 - accuracy: 0.6587\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 1.0390 - accuracy: 0.6604\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.9192 - accuracy: 0.6860\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.9407 - accuracy: 0.6188\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.8041 - accuracy: 0.6822\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.8452 - accuracy: 0.6560\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.7387 - accuracy: 0.6971\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.7361 - accuracy: 0.6690\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.7314 - accuracy: 0.6713\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.7022 - accuracy: 0.6687\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6284 - accuracy: 0.6872\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6181 - accuracy: 0.6765\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6685\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6182 - accuracy: 0.6995\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5761 - accuracy: 0.7128\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6678 - accuracy: 0.6642\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.7293\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.7089\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6022 - accuracy: 0.6993\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6236 - accuracy: 0.7122\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6335 - accuracy: 0.6987\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5951 - accuracy: 0.6694\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6064 - accuracy: 0.6946\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6211 - accuracy: 0.6855\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.6619\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5970 - accuracy: 0.7186\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.7193\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6221 - accuracy: 0.6957\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7244\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5943 - accuracy: 0.7175\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7554\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.6922\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5827 - accuracy: 0.7355\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5516 - accuracy: 0.7192\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7040\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5455 - accuracy: 0.7275\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7237\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7500\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.7450\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7183\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5999 - accuracy: 0.6810\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5404 - accuracy: 0.7142\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.7468\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5441 - accuracy: 0.7400\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7240\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5454 - accuracy: 0.7100\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7549\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5363 - accuracy: 0.7280\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.6970\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5345 - accuracy: 0.7617\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5324 - accuracy: 0.7437\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5440 - accuracy: 0.7200\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.7182\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7312\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5453 - accuracy: 0.7119\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5382 - accuracy: 0.7213\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.7489\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7219\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5399 - accuracy: 0.7326\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5355 - accuracy: 0.7302\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5418 - accuracy: 0.7644\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7056\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7684\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7667\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5294 - accuracy: 0.7247\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7482\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7159\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7191\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5407 - accuracy: 0.7342\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7255\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5223 - accuracy: 0.7600\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5105 - accuracy: 0.7580\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7444\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5564 - accuracy: 0.7372\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5294 - accuracy: 0.7524\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5040 - accuracy: 0.7687\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7593\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5543 - accuracy: 0.7393\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5308 - accuracy: 0.7271\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7233\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7543\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7292\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.7338\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7697\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.7480\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7474\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7343\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7335\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7541\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.7674\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5556 - accuracy: 0.7147\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.7605\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7531\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7374\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7049\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4987 - accuracy: 0.7648\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7616\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5063 - accuracy: 0.7520\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.7386\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7644\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7104\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5167 - accuracy: 0.7530\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5048 - accuracy: 0.7541\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5228 - accuracy: 0.7517\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.7657\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7625\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7919\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7823\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7357\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.7242\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7664\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7378\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5195 - accuracy: 0.7697\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7861\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7421\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7525\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7628\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5250 - accuracy: 0.7394\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5106 - accuracy: 0.7618\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7625\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.7848\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.7525\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7532\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.7306\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.7334\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5070 - accuracy: 0.7539\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7661\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.7603\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5075 - accuracy: 0.7538\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4796 - accuracy: 0.7718\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.7503\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5271 - accuracy: 0.7445\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7728\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7747\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.7838\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.7628\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5481 - accuracy: 0.7337\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5124 - accuracy: 0.7561\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.7392\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 998us/step - loss: 0.5134 - accuracy: 0.7554\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7526\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.7379\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7202\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4914 - accuracy: 0.7500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd996b2a590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5By7DeH8ebi",
        "outputId": "06dd5d5b-5531-44d2-e4a5-62e78863a4ac"
      },
      "source": [
        "# evalua el modelo\r\n",
        "scores = model.evaluate(X, Y)\r\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.7630\n",
            "\n",
            "accuracy: 76.30%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTjgsumM9IKK",
        "outputId": "e040acb8-23a0-4289-9784-bea54695b5f8"
      },
      "source": [
        "# calcula las predicciones\r\n",
        "predictions = model.predict(X)\r\n",
        "# redondeamos las predicciones\r\n",
        "rounded = [round(x[0]) for x in predictions]\r\n",
        "print(rounded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}